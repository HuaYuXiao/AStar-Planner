







@article{
doi:10.1126/scirobotics.aaz9712,
author = {Davide Falanga  and Kevin Kleber  and Davide Scaramuzza },
title = {Dynamic obstacle avoidance for quadrotors with event cameras},
journal = {Science Robotics},
volume = {5},
number = {40},
pages = {eaaz9712},
year = {2020},
doi = {10.1126/scirobotics.aaz9712},
URL = {https://www.science.org/doi/abs/10.1126/scirobotics.aaz9712},
eprint = {https://www.science.org/doi/pdf/10.1126/scirobotics.aaz9712},
abstract = {Micro-aerial vehicles dodge fast-moving objects using only onboard sensing and computation. Todayâ€™s autonomous drones have reaction times of tens of milliseconds, which is not enough for navigating fast in complex dynamic environments. To safely avoid fast moving objects, drones need low-latency sensors and algorithms. We departed from state-of-the-art approaches by using event cameras, which are bioinspired sensors with reaction times of microseconds. Our approach exploits the temporal information contained in the event stream to distinguish between static and dynamic objects and leverages a fast strategy to generate the motor commands necessary to avoid the approaching obstacles. Standard vision algorithms cannot be applied to event cameras because the output of these sensors is not images but a stream of asynchronous events that encode per-pixel intensity changes. Our resulting algorithm has an overall latency of only 3.5 milliseconds, which is sufficient for reliable detection and avoidance of fast-moving obstacles. We demonstrate the effectiveness of our approach on an autonomous quadrotor using only onboard sensing and computation. Our drone was capable of avoiding multiple obstacles of different sizes and shapes, at relative speeds up to 10 meters/second, both indoors and outdoors.}}

